{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "#use my API key to access twitter using tweepy\n",
    "consumer_key = 'gWOM9f9FtTLgTrwarkVFVZohn'\n",
    "consumer_secret = 'i14AQ4Dryxs0vuA4LalFPv2WykV1L3HbROrtfKWy6gwB1Q0EK2'\n",
    "access_token = '109302020-RKTo6bMnFRSaX2EPbHBPnLLI7pkUplYPSEZVmOMV'\n",
    "access_secret = 'uft6vpBXXVoL4YDpA9M2JZ91Z0tekZjwaEnYJcuDnNkv8'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Player</th>\n",
       "      <th>Twitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acyqu01</td>\n",
       "      <td>Quincy Acy</td>\n",
       "      <td>QuincyAcy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adamsjo01</td>\n",
       "      <td>Jordan Adams</td>\n",
       "      <td>jordanadams1231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adamsst01</td>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>RealStevenAdams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adebaba01</td>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>Bam1of1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adrieje01</td>\n",
       "      <td>Jeff Adrien</td>\n",
       "      <td>Adrien4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID        Player          Twitter\n",
       "0    acyqu01    Quincy Acy        QuincyAcy\n",
       "1  adamsjo01  Jordan Adams  jordanadams1231\n",
       "2  adamsst01  Steven Adams  RealStevenAdams\n",
       "3  adebaba01   Bam Adebayo          Bam1of1\n",
       "4  adrieje01   Jeff Adrien          Adrien4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#page that lists NBA twitter feeds\n",
    "url = \"http://www.basketball-reference.com/friv/twitter.html\"\n",
    "    \n",
    "#scrape the web page using BS\n",
    "req = requests.get(url)\n",
    "d = req.text\n",
    "soup = BeautifulSoup(d, \"lxml\")\n",
    "\n",
    "#get the table\n",
    "table = soup.find_all('table')[0]\n",
    "\n",
    "#blank dict\n",
    "data = {\n",
    "    'Player' : [],\n",
    "    'Twitter' : [],\n",
    "    'ID': []\n",
    "}\n",
    "\n",
    "#add player and twitter feed to dict\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[2:]:\n",
    "    r = row.find_all('a')\n",
    "    #player and twitter feed\n",
    "    data['Player'].append(r[0].get_text())\n",
    "    data['Twitter'].append(r[1].get_text())\n",
    "    #reg ex to extract palyer id\n",
    "    temp = re.search('\\/.\\/(.+?)\\.html', str(r[0]))\n",
    "    data['ID'].append(temp.group(1))\n",
    "    \n",
    "#create a data frame\n",
    "NBAtwitter = pd.DataFrame(data=data)\n",
    "NBAtwitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#page that lists NBA player stats\n",
    "url = \"https://www.basketball-reference.com/leagues/NBA_2017_totals.html\"\n",
    "    \n",
    "#scrape the web page using BS\n",
    "req = requests.get(url)\n",
    "d = req.text\n",
    "soup = BeautifulSoup(d, \"lxml\")\n",
    "\n",
    "#get the table\n",
    "table = soup.find_all('table')[0]\n",
    "\n",
    "#current players\n",
    "currentNBA = []\n",
    "\n",
    "rows = table.find_all('tr')\n",
    "for row in rows[2:]:\n",
    "    r = row.find_all('a')\n",
    "    #skip header rows\n",
    "    if len(r)==0:\n",
    "        continue\n",
    "    #reg ex to extract palyer id\n",
    "    temp = re.search('\\/.\\/(.+?)\\.html', str(r[0]))\n",
    "    currentNBA.append(temp.group(1))\n",
    "    \n",
    "#remove duplicates\n",
    "currentNBA = set(currentNBA)\n",
    "\n",
    "#how many NBA players played in the league last season\n",
    "len(currentNBA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "#only active NBA player twitter feeds\n",
    "currentNBAtwitter = NBAtwitter[NBAtwitter['ID'].isin(currentNBA)].reset_index(drop=True)\n",
    "\n",
    "#how many players have twitter feeds\n",
    "round(len(currentNBAtwitter)/len(currentNBA), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is the code i wrote to get the friends for all NBA players\n",
    "#you can now skip this part and take the csvs straight from my github\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#initialize a dataframe\n",
    "df = pd.DataFrame(data={'src' : [], 'dst' : []})\n",
    "\n",
    "index = -1\n",
    "for each in currentNBAtwitter['Twitter']:\n",
    "    #keep track of progress\n",
    "    index += 1\n",
    "    if index < 1000: #change this number to run\n",
    "        continue\n",
    "    #temp data\n",
    "    g = {'src' : [], 'dst' : []}\n",
    "    counter = 0\n",
    "    ids = []\n",
    "    #go through each page of followers for all our NBA twitter users\n",
    "    for page in tweepy.Cursor(api.friends, screen_name=each, count=200).pages():\n",
    "        ids.extend(page)\n",
    "        print index, currentNBAtwitter['ID'][index], counter\n",
    "        counter += 1\n",
    "        #add the data \n",
    "        src = g['src'].extend([each for i in ids])\n",
    "        dst = g['dst'].extend([user.screen_name for user in ids])\n",
    "        #temp df\n",
    "        df2 = pd.DataFrame(data=g)\n",
    "        #save this to a csv\n",
    "        df2.to_csv('data/nba_twitter/%s_friends.csv' % currentNBAtwitter['ID'][index])\n",
    "    #add the temp data to the original\n",
    "    df = df.append(df2, ignore_index=True)\n",
    "    #save this to a csv - overwrite each time \n",
    "    #change number at the end every restart\n",
    "    df.to_csv('data/nba_twitter/all_nba/nba_twitter_friends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read csv and add to pd data frame - be careful 12m rows\n",
    "base = \"https://raw.githubusercontent.com/capstat/MSDA_620/master/data/nba_twitter/nba_twitter_friends%s.csv\"\n",
    "\n",
    "#initialize a dataframe\n",
    "df = pd.DataFrame(data={'src' : [], 'dst' : []})\n",
    "\n",
    "for i in range(1, 41):\n",
    "    temp = pd.read_csv(base % i)\n",
    "    #drop useless index row\n",
    "    del temp['X']\n",
    "    df = df.append(temp, ignore_index=True)\n",
    "\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use networkx for calculations\n",
    "import networkx as nx\n",
    "\n",
    "g = nx.from_pandas_dataframe(df, source='src', target='dst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#network too big - trim\n",
    "pop = []\n",
    "for each in g.nodes():\n",
    "    if len(g.neighbors(each)) > 20:\n",
    "        pop.append(each)\n",
    "\n",
    "print len(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[df['dst'].isin(pop)]\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#twitter feeds with more than 20 neighbors\n",
    "ns = [x[0] for x in cc]\n",
    "not_player = set(ns) - set(currentNBAtwitter['Twitter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = nx.closeness_centrality(gg)\n",
    "bb = sorted(b.iteritems(), key=lambda (k,v): (-v,k))\n",
    "bbb = [t for t in bb if t[0] in not_player]\n",
    "\n",
    "print \"Betweeness Centrality\"\n",
    "for each in bbb[:10]: print each[0], \": \", each[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = nx.betweenness_centrality(gg)\n",
    "bb = sorted(b.iteritems(), key=lambda (k,v): (-v,k))\n",
    "bbb = [t for t in bb if t[0] in not_player]\n",
    "\n",
    "print \"Betweeness Centrality\"\n",
    "for each in bbb[:10]: print each[0], \": \", each[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = nx.pagerank(gg)\n",
    "bb = sorted(b.iteritems(), key=lambda (k,v): (-v,k))\n",
    "bbb = [t for t in bb if t[0] in not_player]\n",
    "\n",
    "print \"Betweeness Centrality\"\n",
    "for each in bbb[:10]: print each[0], \": \", each[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
